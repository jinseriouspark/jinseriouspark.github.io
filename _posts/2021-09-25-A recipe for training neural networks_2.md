---
layout: post
title: "A recipe for training neural networks 신경망 학습 가이드(2)"
author: "Seriouscoding"
---

오역이 있을시 말씀주시면 수정하겠습니다.

**원제:  recipe for training neural networks** [post url](http://karpathy.github.io/2019/04/25/recipe/)

**저자: Andrej Karpathy**


______________________________________________________________



**The Recipe**

위에서 언급한 두 가지 내용에 따르면, 저는 제 자신을 위한 특별한 프로세스를 개발했는데, 신경망이 새로운 문제를 접할 때 마다 적용하는 것이며, 이 것에 대해 이번에 설명해보겠습니다. 여러분들은 매우 중요한 두 가지 원칙을 가지고 있다는 것을 알 수 있습니다. 특히, 단순한 것에서 복잡한 것으로 만들고, 모든 구체적인 가설을 세우는 단계에서 어떤 일이 일어날지 확인한 후, 어떤 issue를 찾을 때 까지 실험을 통해 검증하거나 조사합니다. 우리가 매우 열심히 방지하려고 하는 것은, 한 번에 많은 'unverified(확인되지않은)' 복잡성이 소개(도입) 되는 것입니다. 이는 버그/잘못을 찾는데 (만약 있다면) 영원히 걸릴 버그/잘못을 도입할 수 밖에 없습니다. 신경망 코드를 작성하는 것이 훈련과 같다면, 매우 작은 학습률과 추측을 사용하고나서, 모든 반복 후에 전체 테스트 세트를 평가하고 싶을 것입니다. 

1. Become one with the data 데이터와 함께 시작하다

신경망을 학습하는 첫번째 단계는, 어떠한 신경망 코드를 한번에 사용하지 않는것입니다. 그 대신에 , 여러분의 데이터 조사를 아주 자세하게 시작하는 것입니다. 이 단계는 매우 중요합니다. 저는 수많은 시간을 (몇 시간 단위로 측정할 수 있는) 수천개의 예시를 스캐닝하고, 그 데이터의 분산을 이해하고, 패턴을 살펴보는데에 사용하였습니다. 운이 좋게도 여러분의 뇌는 이러한 행위를 잘 할 수 있습니다. 데이터가 중복된 예시를 가지고 있다는 것을 발견한 적도 있습니다. 또 어떤 때는 파괴된 이미지나 label을 가지고 있는 것을 발견하기도 하였습니다. 저는 데이터 불균형과 편향을 살펴보기도 하였습니다. 데이터 분류를 위한 제 스스로의 프로세스에 집중하는 것이 일반적입니다. 그리고 이것은 우리가 결국에 조사해야할 아키텍쳐의 종류에 힌트가 될 수 있습니다. 예를 들어서 - 매우 지엽적인 피쳐가 충분히 있거나, 여러분들이 전역적인 콘텍스트를 필요로 한다면요? 얼마나 편차가 크고(=다양하고), 그게 어떤 형태를 가져올까요? 어떤 변형이 가짜이며 사전 처리될 수 있을까요? 공간적 위치가 중요합니까/ 아니면 평균적인 pool링이 필요할까요? 디테일이 얼마나 중요하며, 이미지를 얼마나 다운샘플링 할 수 있을까요? 레이블에는 얼마나 잡음이 섞여있나요?

추가적으로, 신경망이 여러분의 압축된 버전의 데이터셋에 효과적이기 때문에, 여러분의 신경망의 (잘못된) 예측을 발견할 수도 있으며, 그 결과가 어디서 시작되었는지 이해할 수 있습니다. 그리고 네트워크가 데이터에서 본 것과 일치하지 않는 것으로 보이는 예측을 제공한다면 뭔가 잘못된 것입니다. 

한번 데이터에 대한 좋은 감각(직관)을 가지게 된다면, 이는 여러분이 생각할 수 있는 모든 것(라벨의 종류, annotation의 크기, annotation의 갯수 등)을 검색하고, 필터링하고, 분류하는 몇 가지 간단한 코드를 작성하는데 좋은 아이디어가 될 것입니다. 그리고 그들의 분산이나 이상치를 어떤 축에 따라 시각화 하는데에도 도움이 될 것입니다. 이상치는 특히 거의 항상 데이터 품질이나 전처리 하는 과정에서 일부 버그를 보여줍니다.