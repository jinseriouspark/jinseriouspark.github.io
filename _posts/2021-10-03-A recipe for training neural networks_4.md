---
layout: post
title: "A recipe for training neural networks 신경망 학습 가이드(3)"
author: "Seriouscoding"
---

오역이 있을시 말씀주시면 수정하겠습니다.

**원제:  recipe for training neural networks** [post url](http://karpathy.github.io/2019/04/25/recipe/)

**저자: Andrej Karpathy**


______________________________________________________________

3. Overfit
    
    이번 단계에서, 우리는 데이터셋에 대한 좋은 이해가 필요하며, 전체 학습 + 평가 파이프라인을 다룰 것입니다. 우리가 신뢰할 수 있는 metric 을 (재현 가능하게) 계산할 수 있는 어떤 모델이든 말입니다. 우리는 인풋-독립적인 베이스라인에 대한 성능, 몇 가지 바보같은 베이스라인의 성능 (이것보단 잘해야 함)을 가지고 있으며, 사람 평가(실제로 도달하고 싶은 목표) 에 대한 대략적인 감각도 있습니다. 이제 좋은 모델을 반복하기 위한 단계를 모두 갖췄습니다.

이 좋은 모델을 찾기 위해 기꺼이 할 이 접근은 두 단계로 구성되어있습니다: 먼저, 모델이 오버핏(예: 학습 오차에 집중) 될 수 있도록 충분한 크기로 만들어 두세요, 그리고 적절하게 정규화를 진행하세요( 검증 오차를 개선하기 위해 학습 오차를 포기할 수 있을 정도로). 제가 두 단계를 좋아하는 이유는, 우리는 특정 이슈, 버그, 잘못된 설정 오류들로 인해 낮은 에러율 때문에 어떠한 모델로도 낮은 에러율에 도달할 수 없기 때문입니다.

몇가지 팁과 트릭이 있습니다

- picking the model 모델을 선택하세요
    
    좋은 학습 오차에 도달하기 위해 여러분의 데이터에 맞는 적절한 설계 구조를 선택하기를 원할 것입니다. #1의 조언에서 말한 것과 같이, 영웅이 되려고 하지 마십시오(Don't be a hero). 저는 수 많은 사람들이, 그들에게 합리적이라고 보이는 다양하게 특이한 아키텍쳐 속의 툴박스에서 신경망 레고 블록을 가득 쌓는 창의성을 보이거나 그것에 미칠정도의 열정을 가진 사람들을 많이 보았습니다. 여러분의 프로젝트 초기 단계에서 그러한 유혹에 강하게 저항하십시오. 저는 언제나 사람들에게 가장 관련성 높은 논문을 찾으라고 조언하고, 좋은 퍼포먼스를 기록한 간단한 아키텍쳐를 그대로 복사 붙여넣기 하라고 이야기를 합니다. 예를들어, 여러분이 이미지를 분석할 때, 영웅이 되지 않고 ResNet-50 데이터를 단순 복사 붙여넣기하여 처음 실행한다고 생각해보세요. 여러분들은 다음에 더 개인화 할 수 있으며 결국 이것을 해결할 수 있을 것입니다. 
    
- adam is safe 아담은 안전합니다
    
    베이스라인을 셋팅하는 초기 단계에서, 저는 학습률 3e-4의 Adam을 사용하는 것을 좋아합니다. 제 경험에 비추어 보면, Adam 은 나쁜 학습률을 포함한 수많은 하이퍼 파라미터의 영향력을 없에버리곤 합니다(forgive to hyperparameters). ConvNets에 있어서, 잘 튜닝된 SGD가 거의 언제나 Adam보다 조금 더 나은 성능을 냅니다. 그러나 최적화된 학습률 범위는 더욱 미세하고, 문제 지향적입니다. (기억하세요: 만약 여러분이 RNN을 사용하고, 관련된 시퀀스 모델을 사용하고자 한다면, Adam을 먼저 사용하는 것이 일반적입니다. 여러분의 프로젝트 초기 단계에서, 다시말하자면, 영웅이 되려고 하지 마시고 대부분의 논문이 한 것을 따르세요)
    
- complexify only one at a time 한번에 하나만 복잡하게 하기
    
    여러분의 분류기에 다수의 신호를 넣는다면, 저는 여러분이 하나 하나씩 넣기를 바라며 매 순간마다 여러분이 예상한 것과 같은 수준의 퍼포먼스를 올렸는지 확인하기를 바랍니다. 여러분의 모델에 부엌 싱크대에 던져놓듯이 시작부터 쏟아붙지 마세요. 복잡도를 높히는 다른 방법이 있습니다. - 여러분이 작은 이미지를 먼저 넣어보려는 시도를 한 뒤에 더 큰 이미지를 나중에 넣는 등 말입니다.
