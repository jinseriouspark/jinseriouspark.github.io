---
layout: post
title: "A recipe for training neural networks 신경망 학습 가이드(3)"
author: "Seriouscoding"
---

오역이 있을시 말씀주시면 수정하겠습니다.

**원제:  recipe for training neural networks** [post url](http://karpathy.github.io/2019/04/25/recipe/)

**저자: Andrej Karpathy**


______________________________________________________________

2. Set up the end-to-end training/evaluation skeleton + get dumb baseline

이제 우리의 데이터를 이해했으므로, super fancy Multi-scale ASPP FPN ResNet (엄청 멋진 멀티 스케일 ASPP FPN ResNet)에 접근해서 멋진 모델 학습을 시작할 수 있을까요? 확실히 아닙니다. 아직 고난의 행군 중입니다. 우리의 다음 단계는 전체 학습 + 얼개 평가를 위한 셋팅이고, 몇개의 연속된 실험을 통한 그 정확성에 신뢰를 얻는 것입니다. 이 단계에서는 몇가지 단순한 모델에서 최고를 뽑는데, 이 모델들은 어떤 짓을 하더라도 망칠 가능성이 없는 것들입니다. 예를들어 선형 분류기나 매우 작은 ConvNet 같은 것 말입니다. 우리는 이를 학습하고, 오차나 다른 모든 메트릭(예: 정확도) 를 시각화 하고, 모델 예측을 수행하는 과정에서 명백한 가설을 사용하여 일련의 절제 실험을 수행하려고 합니다. 

이 단계에서의 tip 과 trick 들은 다음과 같습니다. 

- fix random seed 랜덤 시드 고정

    언제나 고정된 랜덤 시드를 사용하는 것은 여러분들이 코드를 2회 사용할 때 동일한 결과가 나오게 하는 것을 보장합니다. 이는 변동을 주는 요소를 제거해주고, 여러분들이 미치지 않게끔 도와줍니다. (keep you sane)

- simplify 단순화

    멋지지만 불필요한 것들(any unnecessary fanciness)을 사용하지 못한다는 것을 확실히 하세요. 예를 들어서, 이번 단계에서 데이터 증강을 시도하지 마십시오 (turn off any data augmentation). 데이터 증강은 정규화 전략이며, 이는 이후에 사용할 것입니다. 지금은 그냥 몇가지 멍청한 버그를 소개하는 기회일 뿐입니다. 

- add significant digits to your eval eval에 유효한 숫자 추가

    테스트 오차 그림을 그릴 때, 전체 (큰) 테스트셋에 대한 평가를 실행하게 됩니다. 그때, 각 배치마다의 테스트 손실을 그리지 말고, Tensorboard의 smoothing에만 의존하지 마세요. 우리는 정확성을 추구하며, 제정신을 유지하기 위해 시간을 기꺼이 포기해야 합니다.

- verify loss @ init 초기화 시 loss 확인

    정확한 loss value 에서 여러분의 loss 가 시작했다는 것을 꼭 확인하세요. 예를들어, 만약 여러분의 최종 레이어를 정확하게 초기화 했다면, 여러분은 초기화 과정에서 소프트맥스에 대해 `log(1/n_classes)` 를 계산해야 합니다. 이 동일한 기본값은 L2 회귀, Huber losses 에서도 도출할 수 있습니다.

- init well 잘 초기화하기

    최종 레이어 가중치를 정확하게 초기화 하세요. 예를들어, 만약 여러분이 평균을 50으로 갖는 값들을 초기화 하는 대신 최종 편향을 50으로 하는 값으로 한다면 어떨까요. 만약 여러분이 긍정 : 부정의 비율이 1:10으로 불균형하게 구성된 데이터셋을 갖는다면, 초기화 할 때 여러분의 네트워크가 확률 0.1을 갖도록 여러분의 logit에 대한 편향을 셋팅하세요. 정확하게 셋팅하는 것은 수렴하는 것을 빠르게 하고, 첫번째 몇가지 반복이 기본적으로 편향을 학습하였을 때 보이는 hockey stick 모양의 오차 커브를 없엘 것입니다.

- human baseline 사람 베이스라인

    사람이 해석하고 확인할 수 있는 손실 이외의 메트릭(예를 들어 정확도) 를 모네터링 하세요. 가능할 때마다 자신의 (사람) 정확도를 평가하고 비교하세요. 또는 테스트 데이터에 두번 주석을 달고 각 예제에 대해 하나의 주석을 예측으로 처리하고, 두번째 주석을 실제로 처리하세요.

- input-indepent baseline 인풋 독립적인 베이스라인
    
    입력값에서 독립적인 베이스라인을 학습하세요. (예를들어 가장 쉬운 것은 모든 여러분의 입력값을 0으로 셋팅하는 것이 있습니다.) 이는 만약 여러분이 실제 데이터를 0으로 두지 않았을 때보다 더 안좋은 것을 수행할 수 있습니다. 정말 그럴까요? 예를들어, 여러분의 모델이 인풋과 전혀 관련없는 아무 정보나 반환한다면 어떨까요?
    
- overfit one batch 배치 1개에 과대적합
    
    몇 가지 예시를 가진 단일 배치(최소 2개)에 과대적합 해보세요. 이를 위해서 우리의 모델의 용량(레이어나 필터를 추가 하는 등) 은 늘어날 것이고, 우리가 가장 낮게 얻을 수 있는 손실(예를 들면 0) 에 도달할 수 있다는 것을 확인할 수 있습니다. 저는 동일한 plot 에서 라벨과 예측값을 시각화 하고, 우리가 최저 손실에 도달했을 때 완벽하게 정렬된 것을 확인하는 것을 좋아합니다. 만약 그렇지 않다면, 버그가 어딘가에 있다는 뜻이며, 다음 단계로 넘어갈 수 없습니다.
    
- verfiy decreasing training loss 학습 손실 감소를 확인하세요
    
    이번 단계에서 여러분들은 데이터셋에 과소적합되기를 바랄텐데, 그 이유는 여러분이 토이 모델을 가지고 진행하고 있기 때문입니다. 그 용량을 조금만 더 늘려보세요. 학습 손실이 줄어드나요?  (줄어들어야 함)
    
- visualize just before the net 신경망 넣기 전에 시각화를 하세요
    
    여러분의 데이터를 시각화 하기에 완벽한 장소는 `y_hat = model(x)` (or `[sess.run](http://sess.run)` in tf) 입니다. 즉 여러분들은, 여러분의 신경망에 넣기 전에 어떤 일이 일어나는지, 데이터의 raw tensor 를 디코딩하고 라벨을 시각화함으로써 정확하게 시각화 하기를 원할 것입니다. 이는 '진실의 재료' 입니다. 이 방법이 절 구해주었고, 데이터 전처리와 증강 속에서 발생한 문제를 보여준 경험이 셀 수 없이 많습니다.
    
- visualize prediction dynamics 예측 다이나믹을 시각화하세요
    
    저는, 학습 도중에 미리 마련된 테스트 셋에 모델 예측값을 시각화 하는 것을 선호합니다. 어떻게 이러한 예측값들이 움직이는지 보여주는, 이 "dynamics' 은 여러분들에게 어떻게 학습이 진행되는지에 관련한 아주 놀랍게도 좋은 직관을 제공할 것입니다. 만약 그것이 너무 많이 움직이면서 불안정성을 드러낸다면, 많은 경우 신경망이 여러분의 데이터에 적합되는것이 매우 힘들어 하고 있다는 가능성이 있습니다. 매우 낮거나 매우 높은 학습률은 jitter 의 양에서 쉽게 알 수 있습니다.
    
- use backprop to chart dependencies 의존성을 기록하기 위한 역전파 사용
    
    여러분의 딥러닝 코드는 복잡하고, 벡터화하고, 브로드캐스트 기능을 포함할 것입니다. 관련된 일반적인 버그는 사람들이 이를 잘못(`transpose/permute` 대신에 `view` 를 사용) 가져오고, 배치 차원을 고려하지 않고 실수로 정보를 섞는 것에서 발생합니다. 여러분의 신경망이 일반적으로 여전히 학습이 잘 된다는 것은 정말 슬픈 사실인데요, 그 이유는 다른 예시 속 데이터를 무시하는 것을 학습할 수 있기 때문입니다. 이것(그리고 관련한 다른 문제들)을 디버깅 하는 한 가지 방법은 전체 예시 i의 결과 합산에 사소한 loss 를 정해두고, 역전파를 실행하여 인풋값까지 모두 진행하고, 여러분이 i번째 인풋값에 0이 아닌 그라디언트를 얻었는지 확인하는 것입니다. 이 동일한 전략은 여러분의 자동 회귀 모델에서도 사용할 수 있는데, 시간 t 는 1 ~ t-1 에만 의존하게 되는 것과 마찬가지 입니다. 더 일반적으로 이야기를 해보자면, 그라디언트는 여러분의 신경망에 어떤 것들이 걸려있는지 정보를 제공해 주며, 이는 디버깅에 효과적입니다. 
    
- generalize a special case 특별한 경우를 일반화 (구체적인 코드를 만든 다음에 일반화 하여라)
    
    이는 더 일반적인 코딩 팁인데, 사람들은 그들이 관리할 수 있는 수준보다(they can chew) 더 많은 것을 얻으려 (they bite off) 할 때 버그를 만들어, 처음부터 비교적 일반적인 기능을 작성하는 것을 자주 보았습니다. 저는 지금 제가 하고 있는 일에 대해 매우 구체적인 기능을 작성하여 작동하도록 한 다음에, 나중에 동일한 결과를 얻을 수 있도록 일반화 하는 것을 좋아합니다. 종종 이는 벡터화 코드에 적용되며, 거의 항상 루프 버전을 먼저 작성한 다음, 한 번에 한 루프씩 벡터와 된 코드로 변환합니다.