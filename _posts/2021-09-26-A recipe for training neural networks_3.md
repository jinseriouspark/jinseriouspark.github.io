---
layout: post
title: "A recipe for training neural networks 신경망 학습 가이드(3)"
author: "Seriouscoding"
---

오역이 있을시 말씀주시면 수정하겠습니다.

**원제:  recipe for training neural networks** [post url](http://karpathy.github.io/2019/04/25/recipe/)

**저자: Andrej Karpathy**


______________________________________________________________

2. Set up the end-to-end training/evaluation skeleton + get dumb baseline

이제 우리의 데이터를 이해했으므로, super fancy Multi-scale ASPP FPN ResNet (엄청 멋진 멀티 스케일 ASPP FPN ResNet)에 접근해서 멋진 모델 학습을 시작할 수 있을까요? 확실히 아닙니다. 아직 고난의 행군 중입니다. 우리의 다음 단계는 전체 학습 + 얼개 평가를 위한 셋팅이고, 몇개의 연속된 실험을 통한 그 정확성에 신뢰를 얻는 것입니다. 이 단계에서는 몇가지 단순한 모델에서 최고를 뽑는데, 이 모델들은 어떤 짓을 하더라도 망칠 가능성이 없는 것들입니다. 예를들어 선형 분류기나 매우 작은 ConvNet 같은 것 말입니다. 우리는 이를 학습하고, 오차나 다른 모든 메트릭(예: 정확도) 를 시각화 하고, 모델 예측을 수행하는 과정에서 명백한 가설을 사용하여 일련의 절제 실험을 수행하려고 합니다. 

이 단계에서의 tip 과 trick 들은 다음과 같습니다. 

- fix random seed 랜덤 시드 고정

    언제나 고정된 랜덤 시드를 사용하는 것은 여러분들이 코드를 2회 사용할 때 동일한 결과가 나오게 하는 것을 보장합니다. 이는 변동을 주는 요소를 제거해주고, 여러분들이 미치지 않게끔 도와줍니다. (keep you sane)

- simplify 단순화

    멋지지만 불필요한 것들(any unnecessary fanciness)을 사용하지 못한다는 것을 확실히 하세요. 예를 들어서, 이번 단계에서 데이터 증강을 시도하지 마십시오 (turn off any data augmentation). 데이터 증강은 정규화 전략이며, 이는 이후에 사용할 것입니다. 지금은 그냥 몇가지 멍청한 버그를 소개하는 기회일 뿐입니다. 

- add significant digits to your eval eval에 유효한 숫자 추가

    테스트 오차 그림을 그릴 때, 전체 (큰) 테스트셋에 대한 평가를 실행하게 됩니다. 그때, 각 배치마다의 테스트 손실을 그리지 말고, Tensorboard의 smoothing에만 의존하지 마세요. 우리는 정확성을 추구하며, 제정신을 유지하기 위해 시간을 기꺼이 포기해야 합니다.

- verify loss @ init 초기화 시 loss 확인

    정확한 loss value 에서 여러분의 loss 가 시작했다는 것을 꼭 확인하세요. 예를들어, 만약 여러분의 최종 레이어를 정확하게 초기화 했다면, 여러분은 초기화 과정에서 소프트맥스에 대해 `log(1/n_classes)` 를 계산해야 합니다. 이 동일한 기본값은 L2 회귀, Huber losses 에서도 도출할 수 있습니다.

- init well 잘 초기화하기

    최종 레이어 가중치를 정확하게 초기화 하세요. 예를들어, 만약 여러분이 평균을 50으로 갖는 값들을 초기화 하는 대신 최종 편향을 50으로 하는 값으로 한다면 어떨까요. 만약 여러분이 긍정 : 부정의 비율이 1:10으로 불균형하게 구성된 데이터셋을 갖는다면, 초기화 할 때 여러분의 네트워크가 확률 0.1을 갖도록 여러분의 logit에 대한 편향을 셋팅하세요. 정확하게 셋팅하는 것은 수렴하는 것을 빠르게 하고, 첫번째 몇가지 반복이 기본적으로 편향을 학습하였을 때 보이는 hockey stick 모양의 오차 커브를 없엘 것입니다.

- human baseline 사람 베이스라인

    사람이 해석하고 확인할 수 있는 손실 이외의 메트릭(예를 들어 정확도) 를 모네터링 하세요. 가능할 때마다 자신의 (사람) 정확도를 평가하고 비교하세요. 또는 테스트 데이터에 두번 주석을 달고 각 예제에 대해 하나의 주석을 예측으로 처리하고, 두번째 주석을 실제로 처리하세요.

- input-indepent baseline 인풋 독립적인 베이스라인

    입력값에서 독립적인 베이스라인을 학습하세요. (예를들어 가장 쉬운 것은 모든 여러분의 입력값을 0으로 셋팅하는 것이 있습니다.) 이는 만약 여러분이 실제 데이터를 0으로 두지 않았을 때보다 더 안좋은 것을 수행할 수 있습니다. 정말 그럴까요? 예를들어, 여러분의 모델이 인풋과 전혀 관련없는 아무 정보나 반환한다면 어떨까요?

